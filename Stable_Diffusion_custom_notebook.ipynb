{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stable Diffusion custom notebook",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOrZeyzbUH/cSxb8vi6omHm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/juba/StableDiffusionNotebook/blob/main/Stable_Diffusion_custom_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stable Diffusion custom notebook\n",
        "\n",
        "Sources : \n",
        "\n",
        "- Stable Diffusion Github repo : https://github.com/CompVis/stable-diffusion\n",
        "- Stable Diffusion HugginfaceHub page :https://huggingface.co/CompVis/stable-diffusion-v1-4\n",
        "- Sample Hugginface diffusers notebook : https://colab.research.google.com/github/huggingface/notebooks/blob/main/diffusers/stable_diffusion.ipynb\n",
        "\n",
        "Ressources :\n",
        "\n",
        "- Training set exploration : https://rom1504.github.io/clip-retrieval/"
      ],
      "metadata": {
        "id": "vtn_7PNZqIGH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Setup"
      ],
      "metadata": {
        "id": "xsOuHYu7qR3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.1 Check allocated GPU\n",
        "!nvidia-smi"
      ],
      "metadata": {
        "cellView": "form",
        "id": "mqeDKa9Yqlu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.2 Install Python dependencies\n",
        "!pip install diffusers==0.2.4\n",
        "!pip install transformers scipy ftfy\n",
        "!pip install \"ipywidgets>=7,<8\""
      ],
      "metadata": {
        "cellView": "form",
        "id": "Xlcvoa5kq9G-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.3 Google Drive\n",
        "import os\n",
        "import json\n",
        "from glob import glob\n",
        "\n",
        "use_google_drive = True #@param{type: 'boolean'}\n",
        "\n",
        "if use_google_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  root_path = '/content/drive/MyDrive/AI/Stable_Diffusion'\n",
        "  # Output dir\n",
        "  modelPath = f'{root_path}/models'\n",
        "  os.makedirs(modelPath, exist_ok=True)\n",
        "  # Output dir\n",
        "  outDirPath = f'{root_path}/images_out'\n",
        "  os.makedirs(outDirPath, exist_ok=True)\n",
        "  # Index for file names\n",
        "  file_count = len(glob(outDirPath+\"/*.txt\")) + 1\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "nDpS7uy9yIYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.4 Downloading model\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline\n",
        "\n",
        "use_float16_precision = False#@param {type:\"boolean\"}\n",
        "load_model_from_google_drive = True #@param{type: 'boolean'}\n",
        "save_model_to_google_drive = False #@param{type: 'boolean'}\n",
        "model_subdir = \"float16\" if use_float16_precision else \"float32\"\n",
        "\n",
        "if not(load_model_from_google_drive):\n",
        "  # Load model from Huggingface\n",
        "\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "\n",
        "  from huggingface_hub import notebook_login\n",
        "  notebook_login()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "TCQEUPl1rfCe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "if not(load_model_from_google_drive):\n",
        "  print(f\"Loading model from Huggingface\")\n",
        "  if use_float16_precision:\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      \"CompVis/stable-diffusion-v1-4\", \n",
        "      revision=\"fp16\", torch_dtype=torch.float16, \n",
        "      use_auth_token=True\n",
        "    )\n",
        "  else:\n",
        "    pipe = StableDiffusionPipeline.from_pretrained(\n",
        "      \"CompVis/stable-diffusion-v1-4\", \n",
        "      use_auth_token=True\n",
        "    )\n",
        "  # Optionnaly save it to Drive\n",
        "  if save_model_to_google_drive:\n",
        "    print(f\"Saving model to {modelPath}/{model_subdir}/\")\n",
        "    pipe.save_pretrained(f\"{modelPath}/{model_subdir}/\")\n",
        "\n",
        "else:\n",
        "  print(f\"Loading model from {modelPath}/{model_subdir}/\")\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(f\"{modelPath}/{model_subdir}/\")"
      ],
      "metadata": {
        "cellView": "form",
        "id": "-pldDqrEEgs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 1.5 Utility code and functions\n",
        "\n",
        "from PIL import Image\n",
        "from torch import autocast\n",
        "import random\n",
        "\n",
        "# Move pipeline to GPU\n",
        "pipe = pipe.to(\"cuda\")\n",
        "\n",
        "# Image grid utility\n",
        "def image_grid(imgs, rows, cols):\n",
        "    assert len(imgs) == rows*cols\n",
        "\n",
        "    w, h = imgs[0].size\n",
        "    grid = Image.new('RGB', size=(cols*w, rows*h))\n",
        "    grid_w, grid_h = grid.size\n",
        "    \n",
        "    for i, img in enumerate(imgs):\n",
        "        grid.paste(img, box=(i%cols*w, i//cols*h))\n",
        "    return grid\n",
        "\n",
        "\n",
        "# Do diffusion\n",
        "def do_diffuse(pipe, params):\n",
        "  \n",
        "  num_images = params['images_rows'] * params['images_cols']\n",
        "  prompt = [params['prompt']] * num_images\n",
        "\n",
        "  seed = params['seed']\n",
        "  if seed == -1:\n",
        "    random.seed()\n",
        "    seed = random.randint(0, 2**32)\n",
        "\n",
        "  generator = torch.Generator(\"cuda\").manual_seed(seed)\n",
        "\n",
        "  with autocast(\"cuda\"):\n",
        "    out = pipe(\n",
        "        prompt,\n",
        "        num_inference_steps=params['num_inference_steps'],\n",
        "        guidance_scale=params['guidance_scale'],\n",
        "        width=params['width'],\n",
        "        height=params['height'],\n",
        "        generator=generator\n",
        "    )[\"sample\"]\n",
        "  \n",
        "  if num_images > 1:\n",
        "    out = image_grid(out, rows=params['images_rows'], cols=params['images_cols'])\n",
        "  else:\n",
        "    out = out[0]\n",
        "\n",
        "  return (out, seed)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "WtzZKFJbtO64"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Generate images\n"
      ],
      "metadata": {
        "id": "2yQpSyiotJwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.1 Settings\n",
        "\n",
        "prompt = \"A badass onion superhero\" #@param {type: 'string'}\n",
        "num_inference_steps = 50 #@param{type: 'number'}\n",
        "guidance_scale = 8 #@param{type: 'number'}\n",
        "width = 512 #@param{type: 'number'}\n",
        "height = 512 #@param{type: 'number'}\n",
        "images_rows = 1 #@param{type: 'number'}\n",
        "images_cols = 1 #@param{type: 'number'}\n",
        "seed = -1 #@param{type: 'number'}\n",
        "\n",
        "params = {\n",
        "    'prompt': prompt,\n",
        "    'num_inference_steps': num_inference_steps,\n",
        "    'guidance_scale': guidance_scale,\n",
        "    'width': width,\n",
        "    'height': height,\n",
        "    'images_rows': images_rows,\n",
        "    'images_cols': images_cols,\n",
        "    'use_float16': use_float16_precision,\n",
        "    'seed': seed\n",
        "}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "oZlkZr2qtM3q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title 2.2 Diffuse\n",
        "\n",
        "image, seed = do_diffuse(pipe, params)\n",
        "\n",
        "if use_google_drive:\n",
        "  # Increment index\n",
        "  file_count += 1\n",
        "  # Save settings\n",
        "  seed_orig = params['seed']\n",
        "  params['seed'] = seed\n",
        "  with open(f\"{outDirPath}/img{file_count}_settings.txt\", \"w+\") as f:   #save settings\n",
        "        json.dump(params, f, ensure_ascii=False, indent=4)\n",
        "  # Save image\n",
        "  image.save(f\"{outDirPath}/img{file_count}.jpg\")\n",
        "  params['seed'] = seed_orig\n",
        "  \n",
        "\n",
        "print(f\"Using seed : {seed}\")\n",
        "display(image)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7iTiZCNtumkJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}